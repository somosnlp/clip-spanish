---
language: es
tags:
- multimodal
---

# CLIP Spanish

CLIP-like model trained using the Spanish portion of the WIT dataset during the [Flax x Hugging Face](https://discss.huggingface.co/t/open-to-the-community-community-week-using-jax-flax-for-nlp-cv/7104) community event by
[@mariagrandury](https://github.com/mariagrandury),
[@mrm8488](https://github.com/mrm8488), and
[@edugp](https://github.com/edugp).

## Model description

## Intended uses & limitations

### How to use

### Limitations and bias

## Training data

The model was trained using [WIT](https://arxiv.org/abs/2103.01913) or **W**ikipedia-based **I**mage **Text** dataset, a large multimodal multilingual dataset comprising 37M+ image-text sets with 11M+ unique images across 100+ languages.

### Training procedure

### Eval results
